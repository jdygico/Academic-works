{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f426ec-cc3e-4ffb-85ca-5f64733be603",
   "metadata": {},
   "source": [
    "# Diabetic Population: Data Preparation\n",
    "\n",
    "    Adajar, Beatrice\n",
    "    Dygico, Jacob\n",
    "    Lee, Joan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf89c37-d900-4709-b675-332c8a560019",
   "metadata": {},
   "source": [
    "## Profile Data\n",
    "\n",
    "We will start with reading in the data file and profiling the dataset to get a summary of our data. From there, we will decide on what data cleaning steps are necessary before proceeding to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a96a39-0cc9-40be-9f7a-7f67b61b1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from math import floor\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61edf751-f434-48d8-9037-06498d63c3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bea\\AppData\\Local\\Temp\\ipykernel_4464\\3274348555.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('{}/diabetic_data.csv'.format(file_dir), na_values='?',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)    NaN   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)    NaN   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)    NaN   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)    NaN   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)    NaN   \n",
       "\n",
       "  admission_type_id discharge_disposition_id admission_source_id  \\\n",
       "0                 6                       25                   1   \n",
       "1                 1                        1                   7   \n",
       "2                 1                        1                   7   \n",
       "3                 1                        1                   7   \n",
       "4                 1                        1                   7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = '.'    # replace with your own file directory, if needed\n",
    "df = pd.read_csv('{}/diabetic_data.csv'.format(file_dir), na_values='?',\n",
    "                 dtype={'admission_type_id': str, 'discharge_disposition_id': str,\n",
    "                        'admission_source_id': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b26ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 101766\n",
      "Number of columns: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23609c49-ec60-46a1-acfb-16303ad4907a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"Diabetes Data Report\")\n",
    "# profile.to_file(\"Diabetes Data Report (Initial).html\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a562467",
   "metadata": {},
   "source": [
    "Based on [the paper](https://www.hindawi.com/journals/bmri/2014/781670/) related to the dataset, we will do the following steps:\n",
    "\n",
    "- [ ] Keep only first encounter per `patient_nbr`\n",
    "- [ ] Drop rows of encounters where patient expired or was discharged to a hospice\n",
    "\n",
    "Based on the **Alerts** section, we will perform the following initial data cleaning steps:\n",
    "\n",
    "- [ ] Drop columns with identifier values (not relevant to prediction): <span class=\"label label-info\">encounter_id</span> <span class=\"label label-info\">patient_nbr</span>\n",
    "- [ ] Drop columns with constant values: <span class=\"label label-info\">examide</span> <span class=\"label label-info\">citoglipton</span> <span class=\"label label-info\">glimepiride-pioglitazone</span>\n",
    "- [ ] Drop columns with more than 50% missing values: <span class=\"label label-info\">weight</span>\n",
    "\n",
    "Based on the column values, we need to group together similar values. These steps will help reduce the number of columns:\n",
    "\n",
    "- [ ] Group together values for columns with high cardinality: <span class=\"label label-warning\">diag_1</span> <span class=\"label label-warning\">diag_2</span> <span class=\"label label-warning\">diag_3</span> <span class=\"label label-warning\">medical_specialty</span>\n",
    "- [ ] Group together `'NULL'`, `'Not Mapped'`, `'Not Available'`, and `'Unknown/Invalid'` values for ID columns: <span class=\"label label-warning\">admission_type_id</span> <span class=\"label label-warning\">discharge_disposition_id</span> <span class=\"label label-warning\">admission_source_id</span>\n",
    "\n",
    "Finally, we need to do the following to prep the data for our classification problem:\n",
    "\n",
    "- [ ] Convert categorical columns with meaningful levels to numerical: <span class=\"label label-success\">[all medication columns]</span> <span class=\"label label-success\">age</span> <span class=\"label label-success\">A1Cresult</span> <span class=\"label label-success\">max_glu_serum</span> <span class=\"label label-success\">change</span> <span class=\"label label-success\">diabetesMed</span>\n",
    "- [ ] Dummify remaining categorical columns: <span class=\"label label-success\">race</span> <span class=\"label label-success\">payer_code</span> <span class=\"label label-success\">medical_specialty</span> <span class=\"label label-success\">gender</span> <span class=\"label label-success\">diag_1</span> <span class=\"label label-success\">diag_2</span> <span class=\"label label-success\">diag_3</span>\n",
    "- [ ] Group together `'NO'` and `'>30'` values: <span class=\"label label-success\">readmitted</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec2192",
   "metadata": {},
   "source": [
    "Before performing any of these steps, let us replace the `np.nan` values in our dataframe with the string `'None'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ecc054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d88e1",
   "metadata": {},
   "source": [
    "## Drop Rows\n",
    "\n",
    "- [x] Keep only first encounter per `patient_nbr`\n",
    "- [x] Drop rows of encounters where patient expired or was discharged to a hospice\n",
    "\n",
    "First encounter per patient is determined by the earliest `encounter_id` per `patient_nbr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9477275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after dropping subsequent encounters per patient: 71518\n",
      "Number of rows after dropping patients that expired/were discharged to hospice: 69973\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(['patient_nbr', 'encounter_id']).groupby('patient_nbr').first()\n",
    "print(\"Number of rows after dropping subsequent encounters per patient:\", df.shape[0])\n",
    "df = df[~df['discharge_disposition_id'].isin(['11', '13', '14', '19', '20', '21'])] \n",
    "print(\"Number of rows after dropping patients that expired/were discharged to hospice:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356a3eb",
   "metadata": {},
   "source": [
    "## Drop Columns\n",
    "\n",
    "- [x] Drop columns with identifier values (not relevant to prediction): <span class=\"label label-info\">encounter_id</span> <span class=\"label label-info\">patient_nbr</span>\n",
    "- [x] Drop columns with constant values: <span class=\"label label-info\">examide</span> <span class=\"label label-info\">citoglipton</span>  <span class=\"label label-info\">glimepiride-pioglitazone</span>\n",
    "- [x] Drop columns with more than 50% missing values: <span class=\"label label-info\">weight</span>\n",
    "\n",
    "We start with dropping columns from prediction to decrease the dataframe size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63cb2fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size before dropping columns: 3428677\n",
      "Dataframe size after dropping columns: 3078812\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe size before dropping columns:\", df.size)\n",
    "df.drop(columns=['encounter_id', 'examide', 'citoglipton', 'glimepiride-pioglitazone', 'weight'], axis=1, inplace=True)\n",
    "print(\"Dataframe size after dropping columns:\", df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaba5dc",
   "metadata": {},
   "source": [
    "## Group Similar Values\n",
    "\n",
    "- [x] Group together values for columns with high cardinality: <span class=\"label label-warning\">diag_1</span> <span class=\"label label-warning\">diag_2</span> <span class=\"label label-warning\">diag_3</span> <span class=\"label label-warning\">medical_specialty</span>\n",
    "\n",
    "We need to reduce the cardinality of the diagnosis columns. We can do this by grouping ICD-9 codes following [these categories](http://www.icd9data.com/2006/Volume1/default.htm).\n",
    "\n",
    "The following code will generate new columns <span class=\"label label-warning\">diag_1_group</span>, <span class=\"label label-warning\">diag_2_group</span>, <span class=\"label label-warning\">diag_3_group</span> and drop the original diagnosis columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ed435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_group(code):\n",
    "    \"\"\"Given a diagnosis code and the appropriate dictionary, find and return\n",
    "    the corresponding group of that diagnosis code.\n",
    "    \"\"\"\n",
    "    code = floor(float(re.search(r'\\d+.*', code).group(0)))\n",
    "    \n",
    "# meaning of each ID for each diagnosis code in code_map\n",
    "#     0: 'Infectious And Parasitic Diseases',\n",
    "#     1: 'Neoplasms',\n",
    "#     2: 'Endocrine, Nutritional And Metabolic Diseases, And Immunity Disorders',\n",
    "#     3: 'Diseases Of The Blood And Blood-Forming Organs',\n",
    "#     4: 'Mental Disorders',\n",
    "#     5: 'Diseases Of The Nervous System And Sense Organs',\n",
    "#     6: 'Diseases Of The Circulatory System',\n",
    "#     7: 'Diseases Of The Respiratory System',\n",
    "#     8: 'Diseases Of The Digestive System',\n",
    "#     9: 'Diseases Of The Genitourinary System',\n",
    "#     10: 'Complications Of Pregnancy, Childbirth, And The Puerperium',\n",
    "#     11: 'Diseases Of The Skin And Subcutaneous Tissue',\n",
    "#     12: 'Diseases Of The Musculoskeletal System And Connective Tissue',\n",
    "#     13: 'Congenital Anomalies',\n",
    "#     14: 'Certain Conditions Originating In The Perinatal Period',\n",
    "#     15: 'Symptoms, Signs, And Ill-Defined Conditions',\n",
    "#     16: 'Injury And Poisoning',\n",
    "#     17: 'Supplementary Classification Of Factors Influencing Health Status And Contact With Health Services',\n",
    "#     18: 'Supplementary Classification Of External Causes Of Injury And Poisoning'\n",
    "\n",
    "    codes_map = {\n",
    "        range(1,140): '0',\n",
    "        range(140,240): '1',\n",
    "        range(240,280): '2',\n",
    "        range(280,290): '3',\n",
    "        range(290,320): '4',\n",
    "        range(320,390): '5',\n",
    "        range(390,460): '6',\n",
    "        range(460,520): '7',\n",
    "        range(520,580): '8',\n",
    "        range(580,630): '9',\n",
    "        range(630,680): '10',\n",
    "        range(680,710): '11',\n",
    "        range(710,740): '12',\n",
    "        range(740,760): '13',\n",
    "        range(760,780): '14',\n",
    "        range(780,800): '15',\n",
    "        range(800,1000): '16'\n",
    "    }\n",
    "\n",
    "    for key, value in codes_map.items():\n",
    "        if code in key:\n",
    "            return value\n",
    "\n",
    "def get_group_diagnosis_codes(df, col):\n",
    "    \"\"\"Assign the appropriate group for each diagnosis code for a given column of\n",
    "    diagnosis codes. Returns the updated dataframe.\n",
    "    \"\"\"\n",
    "    col_group = '{}_group'.format(col)\n",
    "    \n",
    "    if col_group not in df.columns:\n",
    "        df[col_group] = 'None'\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if row[col] == 'None':\n",
    "            continue\n",
    "        elif row[col].startswith('V'):\n",
    "            df.loc[idx, col_group] = '17'\n",
    "        elif row[col].startswith('E'): \n",
    "            df.loc[idx, col_group] = '18'\n",
    "        else:\n",
    "            df.loc[idx, col_group] = get_code_group(row[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13878031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69973/69973 [00:40<00:00, 1709.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69973/69973 [00:41<00:00, 1685.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69973/69973 [00:33<00:00, 2062.58it/s]\n"
     ]
    }
   ],
   "source": [
    "diag_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "for col in diag_cols:\n",
    "    df = get_group_diagnosis_codes(df, col)\n",
    "\n",
    "# drop original diagnosis columns\n",
    "df.drop(columns=diag_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d56e2",
   "metadata": {},
   "source": [
    "We will also retain only the top 10 most frequent values under `medical_specialty` and group the rest into an `'Others'` value (excluding missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1253030b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cardiology', 'Others', 'InternalMedicine', 'None',\n",
       "       'Orthopedics-Reconstructive', 'Surgery-General',\n",
       "       'Emergency/Trauma', 'Nephrology', 'Family/GeneralPractice',\n",
       "       'Pulmonology', 'Orthopedics', 'Radiologist'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_specialties(x):\n",
    "    top_medical_specialties = ['InternalMedicine', 'Emergency/Trauma', 'Family/GeneralPractice',\n",
    "                               'Cardiology', 'Surgery-General', 'Nephrology', 'Orthopedics',\n",
    "                               'Orthopedics-Reconstructive', 'Radiologist', 'Pulmonology', 'None']\n",
    "    \n",
    "    if x not in top_medical_specialties:\n",
    "        return 'Others'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df['medical_specialty'] = df['medical_specialty'].apply(map_specialties)\n",
    "df['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c44a1",
   "metadata": {},
   "source": [
    "- [x] Group together `'NULL'`, `'Not Mapped'`, `'Not Available'`, and `'Unknown/Invalid'` values for ID columns: <span class=\"label label-warning\">admission_type_id</span> <span class=\"label label-warning\">discharge_disposition_id</span> <span class=\"label label-warning\">admission_source_id</span>\n",
    "\n",
    "We will also be grouping the listed values as they will all be treated as \"missing\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa5ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = {\n",
    "    'admission_type_id': {'5':'6', '8':'6'},\n",
    "    'discharge_disposition_id': {'25':'18', '26':'18'},\n",
    "    'admission_source_id': {'15':'17', '9':'17', '20':'17', '21':'17'}\n",
    "}\n",
    "\n",
    "for key, value in id_map.items():\n",
    "    df[key] = df[key].apply(lambda x: str(value[x]) if x in value.keys() else str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d2b9c",
   "metadata": {},
   "source": [
    "## Modify Columns for Classification\n",
    "\n",
    "- [x] Convert categorical columns with meaningful levels to numerical: <span class=\"label label-success\">[all medication columns]</span> <span class=\"label label-success\">age</span> <span class=\"label label-success\">A1Cresult</span> <span class=\"label label-success\">max_glu_serum</span> <span class=\"label label-success\">change</span> <span class=\"label label-success\">diabetesMed</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2bfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps of categorical values to numerical values\n",
    "medication_map = {'No': 0, 'Down': 1, 'Steady': 2, 'Up': 3}\n",
    "age_map = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45,\n",
    "           '[50-60)': 55, '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
    "A1Cresult_map = {'None': 0, 'Norm': 1, '>7': 2, '>8':3}\n",
    "max_glu_serum_map = {'None': 0, 'Norm': 1, '>200': 2, '>300': 3}\n",
    "change_map = {'No': 0, 'Ch': 1}\n",
    "diabetesMed_map = {'No': 0, 'Yes': 1}\n",
    "\n",
    "# list of columns to map\n",
    "medication_columns = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "                      'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "                      'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'insulin',\n",
    "                      'glyburide-metformin', 'glipizide-metformin', 'metformin-rosiglitazone',\n",
    "                      'metformin-pioglitazone']\n",
    "columns_to_map = ['age', 'A1Cresult', 'max_glu_serum', 'change', 'diabetesMed']\n",
    "map_list = [age_map, A1Cresult_map, max_glu_serum_map, change_map, diabetesMed_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "491cf757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(columns_to_map):\n",
    "    df[col] = df[col].map(map_list[idx])\n",
    "\n",
    "for col in medication_columns:\n",
    "    df[col] = df[col].map(medication_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf3869",
   "metadata": {},
   "source": [
    "- [x] Dummify remaining categorical columns: <span class=\"label label-success\">race</span> <span class=\"label label-success\">payer_code</span> <span class=\"label label-success\">medical_specialty</span> <span class=\"label label-success\">gender</span> <span class=\"label label-success\">diag_1</span> <span class=\"label label-success\">diag_2</span> <span class=\"label label-success\">diag_3</span>\n",
    "\n",
    "We apply one-hot encoding to columns with categorical values. We will then drop one column per category to obtain `k-1` dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7d74c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.get_dummies(df.drop(columns='readmitted'))\n",
    "df_final = pd.merge(df['readmitted'], df_final, left_index=True, right_index=True)\n",
    "df_final.drop(columns=['race_None', 'payer_code_None', 'medical_specialty_None',\n",
    "                       'gender_Unknown/Invalid', 'diag_1_group_None', 'diag_2_group_None',\n",
    "                       'diag_3_group_None'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea864f",
   "metadata": {},
   "source": [
    "- [x] Group together `'NO'` and `'>30'` values: <span class=\"label label-success\">readmitted</span>\n",
    "\n",
    "Finally, we modify the label column to be a binary class problem. Since our concern is readmission within 30 days, we will map `'<30'` to `1` and everything else to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01196dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63696\n",
       "1     6277\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['readmitted'] = df_final['readmitted'].map({'NO': 0, '>30': 0, '<30': 1})\n",
    "df_final['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392446e",
   "metadata": {},
   "source": [
    "## Save New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d460d",
   "metadata": {},
   "source": [
    "We can also generate a report of the new dataset to view a summary after the transformations we applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a166ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df_final, title=\"Diabetes Data Report\")\n",
    "# profile.to_file(\"Diabetes Data Report (Final).html\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b02b6",
   "metadata": {},
   "source": [
    "We will now split the data into train-test files and pickle them for modeling later. Since the dataset is imbalanced (88.8% not readmitted, 11.6% readmitted), we will do a stratified train-test split.\n",
    "\n",
    "To account for the class imbalance during training, we will use SMOTE to oversample the minority class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cb6ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "[(0, 38217), (1, 3766)]\n",
      "Class distribution after SMOTE:\n",
      "[(0, 38217), (1, 38217)]\n",
      "Class distribution after SMOTETomek:\n",
      "[(0, 38186), (1, 38186)]\n",
      "Class distribution after SMOTEENN:\n",
      "[(0, 13336), (1, 37964)]\n"
     ]
    }
   ],
   "source": [
    "# split data into train-test\n",
    "t_size = 0.4\n",
    "X = df_final.drop(columns=['readmitted'], axis=1)\n",
    "y = df_final['readmitted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=0, stratify=df_final['readmitted'])\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(sorted(Counter(y_train).items()))\n",
    "\n",
    "# oversample minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=2022)\n",
    "X_train1, y_train1 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(sorted(Counter(y_train1).items()))\n",
    "\n",
    "# mixed oversample minority class + undersample majority class using SMOTETomek\n",
    "smote = SMOTETomek(random_state=2022)\n",
    "X_train2, y_train2 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTETomek:\")\n",
    "print(sorted(Counter(y_train2).items()))\n",
    "\n",
    "# mixed oversample minority class + undersample majority class using SMOTEENN\n",
    "smote = SMOTEENN(random_state=2022)\n",
    "X_train3, y_train3 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTEENN:\")\n",
    "print(sorted(Counter(y_train3).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c5c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle files\n",
    "data_dir = './data' # replace with your own file directory, if needed\n",
    "X_train3.to_pickle('{}/X_train.pkl'.format(data_dir))     # change X_train to variable depending on chosen sampling method\n",
    "X_test.to_pickle('{}/X_test.pkl'.format(data_dir))\n",
    "y_train3.to_pickle('{}/y_train.pkl'.format(data_dir))\n",
    "y_test.to_pickle('{}/y_test.pkl'.format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f44405d",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "We will also create a separate dataset where we perform PCA and compare the results. Note that the number of components we choose will correspond to 90% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bceaef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_features = df_final.drop(columns='readmitted')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_rescaled = scaler.fit_transform(df_features)\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "pca.fit(data_rescaled)\n",
    "reduced = pca.transform(data_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78043493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.073826</td>\n",
       "      <td>-0.487091</td>\n",
       "      <td>0.611997</td>\n",
       "      <td>0.123178</td>\n",
       "      <td>0.726414</td>\n",
       "      <td>-0.388446</td>\n",
       "      <td>-0.459743</td>\n",
       "      <td>0.339648</td>\n",
       "      <td>0.284738</td>\n",
       "      <td>0.610278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129785</td>\n",
       "      <td>-0.185195</td>\n",
       "      <td>0.094374</td>\n",
       "      <td>0.135401</td>\n",
       "      <td>0.318169</td>\n",
       "      <td>0.331017</td>\n",
       "      <td>0.063520</td>\n",
       "      <td>0.653091</td>\n",
       "      <td>-0.124378</td>\n",
       "      <td>0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.247766</td>\n",
       "      <td>-0.845708</td>\n",
       "      <td>-0.808020</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.422334</td>\n",
       "      <td>-0.697335</td>\n",
       "      <td>0.087451</td>\n",
       "      <td>-0.531083</td>\n",
       "      <td>-0.522133</td>\n",
       "      <td>-0.069375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067710</td>\n",
       "      <td>-0.075374</td>\n",
       "      <td>0.115559</td>\n",
       "      <td>-0.112575</td>\n",
       "      <td>0.114162</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>-0.150462</td>\n",
       "      <td>0.133061</td>\n",
       "      <td>-0.342664</td>\n",
       "      <td>-0.157979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.958929</td>\n",
       "      <td>-0.757357</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.782760</td>\n",
       "      <td>-0.832384</td>\n",
       "      <td>0.119101</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>-0.359732</td>\n",
       "      <td>0.324111</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080763</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>-0.098346</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>-0.018690</td>\n",
       "      <td>-0.118191</td>\n",
       "      <td>-0.090133</td>\n",
       "      <td>-0.017387</td>\n",
       "      <td>-0.067647</td>\n",
       "      <td>0.023735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.878131</td>\n",
       "      <td>-0.346876</td>\n",
       "      <td>0.342805</td>\n",
       "      <td>0.195924</td>\n",
       "      <td>0.737271</td>\n",
       "      <td>-0.121768</td>\n",
       "      <td>-0.681246</td>\n",
       "      <td>0.152436</td>\n",
       "      <td>-0.087569</td>\n",
       "      <td>-0.806423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.117945</td>\n",
       "      <td>0.036786</td>\n",
       "      <td>0.094410</td>\n",
       "      <td>-0.098926</td>\n",
       "      <td>-0.035077</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.071760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.989832</td>\n",
       "      <td>-0.756759</td>\n",
       "      <td>-0.335043</td>\n",
       "      <td>-1.150972</td>\n",
       "      <td>0.324396</td>\n",
       "      <td>-0.094022</td>\n",
       "      <td>0.683105</td>\n",
       "      <td>-0.129843</td>\n",
       "      <td>0.029809</td>\n",
       "      <td>-0.018579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272370</td>\n",
       "      <td>0.107550</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>-0.127839</td>\n",
       "      <td>-0.069921</td>\n",
       "      <td>-0.100507</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.149092</td>\n",
       "      <td>-0.281492</td>\n",
       "      <td>0.133402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  1.073826 -0.487091  0.611997  0.123178  0.726414 -0.388446 -0.459743   \n",
       "1  1.247766 -0.845708 -0.808020 -0.630327 -0.422334 -0.697335  0.087451   \n",
       "2 -0.958929 -0.757357  0.003695  0.782760 -0.832384  0.119101  0.134851   \n",
       "3 -0.878131 -0.346876  0.342805  0.195924  0.737271 -0.121768 -0.681246   \n",
       "4 -0.989832 -0.756759 -0.335043 -1.150972  0.324396 -0.094022  0.683105   \n",
       "\n",
       "         7         8         9   ...        50        51        52        53  \\\n",
       "0  0.339648  0.284738  0.610278  ...  0.129785 -0.185195  0.094374  0.135401   \n",
       "1 -0.531083 -0.522133 -0.069375  ...  0.067710 -0.075374  0.115559 -0.112575   \n",
       "2 -0.359732  0.324111 -0.019120  ... -0.080763  0.062845 -0.098346  0.020104   \n",
       "3  0.152436 -0.087569 -0.806423  ... -0.001618 -0.117945  0.036786  0.094410   \n",
       "4 -0.129843  0.029809 -0.018579  ...  0.272370  0.107550  0.100200 -0.127839   \n",
       "\n",
       "         54        55        56        57        58        59  \n",
       "0  0.318169  0.331017  0.063520  0.653091 -0.124378  0.006021  \n",
       "1  0.114162  0.171453 -0.150462  0.133061 -0.342664 -0.157979  \n",
       "2 -0.018690 -0.118191 -0.090133 -0.017387 -0.067647  0.023735  \n",
       "3 -0.098926 -0.035077 -0.037398  0.029968  0.000110 -0.071760  \n",
       "4 -0.069921 -0.100507  0.104900  0.149092 -0.281492  0.133402  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca = pd.DataFrame(reduced)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75327c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.093, 0.07 , 0.056, 0.05 , 0.046, 0.039, 0.038, 0.032, 0.028,\n",
       "       0.025, 0.024, 0.02 , 0.019, 0.019, 0.016, 0.016, 0.015, 0.014,\n",
       "       0.014, 0.013, 0.012, 0.011, 0.011, 0.01 , 0.01 , 0.01 , 0.009,\n",
       "       0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.007, 0.007, 0.007,\n",
       "       0.006, 0.006, 0.006, 0.006, 0.006, 0.006, 0.005, 0.005, 0.005,\n",
       "       0.005, 0.005, 0.005, 0.005, 0.005, 0.004, 0.004, 0.004, 0.004,\n",
       "       0.004, 0.004, 0.004, 0.004, 0.004, 0.003])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2cacbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69973, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31789e1f",
   "metadata": {},
   "source": [
    "## Save New Dataset (PCA)\n",
    "\n",
    "We will now split the data into train-test files and pickle them for modeling later. Since the dataset is imbalanced (88.8% not readmitted, 11.6% readmitted), we will do a stratified train-test split.\n",
    "\n",
    "To account for the class imbalance during training, we will use SMOTE to oversample the minority class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c934b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "[(0, 38217), (1, 3766)]\n",
      "Class distribution after SMOTE:\n",
      "[(0, 38217), (1, 38217)]\n",
      "Class distribution after SMOTETomek:\n",
      "[(0, 38189), (1, 38189)]\n",
      "Class distribution after SMOTEENN:\n",
      "[(0, 21560), (1, 37809)]\n"
     ]
    }
   ],
   "source": [
    "# split data into train-test\n",
    "t_size = 0.4\n",
    "X = df_pca\n",
    "y = df_final['readmitted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=0, stratify=df_final['readmitted'])\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(sorted(Counter(y_train).items()))\n",
    "\n",
    "# oversample minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=2022)\n",
    "X_train1, y_train1 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(sorted(Counter(y_train1).items()))\n",
    "\n",
    "# mixed oversample minority class + undersample majority class using SMOTETomek\n",
    "smote = SMOTETomek(random_state=2022)\n",
    "X_train2, y_train2 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTETomek:\")\n",
    "print(sorted(Counter(y_train2).items()))\n",
    "\n",
    "# mixed oversample minority class + undersample majority class using SMOTEENN\n",
    "smote = SMOTEENN(random_state=2022)\n",
    "X_train3, y_train3 = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTEENN:\")\n",
    "print(sorted(Counter(y_train3).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ba62a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle files\n",
    "data_dir = './data' # replace with your own file directory, if needed\n",
    "X_train3.to_pickle('{}/X_train_PCA.pkl'.format(data_dir))     # change X_train to variable depending on chosen sampling method\n",
    "X_test.to_pickle('{}/X_test_PCA.pkl'.format(data_dir))\n",
    "y_train3.to_pickle('{}/y_train_PCA.pkl'.format(data_dir))\n",
    "y_test.to_pickle('{}/y_test_PCA.pkl'.format(data_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
